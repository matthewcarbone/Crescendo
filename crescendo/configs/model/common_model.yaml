dropout: 0.0
activation:
  _target_: torch.nn.ReLU
last_activation: null
batch_norm: True
last_batch_norm: False

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.001
  # Can add log10_lr instead!
  weight_decay: 0.0

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.95
  patience: 10

lr_scheduler_kwargs:
  monitor: "val/loss"
  interval: epoch
  frequency: 1

criterion:
  _target_: torch.nn.MSELoss

# How often to print the losses to the console
print_every: 20
